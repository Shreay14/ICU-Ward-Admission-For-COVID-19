# -*- coding: utf-8 -*-
"""COVID19 ICU Admission

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1B_8JHcUGVuZOmhGFSMprKsFi3XoS14xr

# COVID-19 ICU Admission

COVID-19 pandemic impacted the whole world, overwhelming healthcare systems - unprepared for such intense and lengthy request for ICU beds, professionals, personal protection equipment and healthcare resources.
Brazil recorded first COVID-19 case on February 26 and reached community transmission on March 20.

Based on the data available, is it feasible to predict which patients will need intensive care unit support?
The aim is to provide tertiary and quarternary hospitals with the most accurate answer, so ICU resources can be arranged or patient transfer can be scheduled.

# Dataset
This dataset contains anonymized data from Hospital Sírio-Libanês, São Paulo and Brasilia. All data were anonymized following the best international practices and recommendations. Data has been cleaned and scaled by column according to Min Max Scaler to fit between -1 and 1.
"""

#importing the libraries
import numpy as np
import pandas as pd
import tensorflow as tf

#importing the dataset
dataset = pd.read_excel('Kaggle_Sirio_Libanes_ICU_Prediction.xlsx')
dataset = pd.DataFrame(dataset)


#Removing the unnecessary columns
dataset.drop(["AGE_PERCENTIL"], axis = 1, inplace = True)
dataset = dataset[dataset.columns.drop(list(dataset.filter(regex='_MEAN')))]
dataset = dataset[dataset.columns.drop(list(dataset.filter(regex='_MIN')))]
dataset = dataset[dataset.columns.drop(list(dataset.filter(regex='_MAX')))]
dataset = dataset[dataset.columns.drop(list(dataset.filter(regex='_DIFF')))]


#encoding the range like parameters with numerals
'''we have encoded:
0-2 as 1
2-4 as 2 
4-6 as 3
6-12 as 4
ABOVE_12 as 5'''
dataset["WINDOW"].replace({"0-2": "1", "2-4": "2","4-6": "3","6-12": "4","ABOVE_12": "5"}, inplace=True)
dataset["GENDER"].replace({1 : 1.0, 0 : 0.0},inplace = True)
dataset["AGE_ABOVE65"].replace({1 : 1.0, 0 : 0.0},inplace = True)


#Splitting into dependant and independant variable sets
X = dataset.iloc[:,:-1]
Y = dataset.iloc[:,54]


#Removing the infinite and null values
X = X.replace([np.inf, -np.inf],np.nan) #removing the infinite values
X = X.replace(np.nan,9) #replacing the null values with 9(any random number)


#Filling the missing values
X=np.asarray(X).astype(np.float32)
Y=np.asarray(Y).astype(np.float32)
from sklearn.impute import SimpleImputer
imputer = SimpleImputer(missing_values=9, strategy='mean') #now treat 9 as missing values
imputer = imputer.fit(X[:,11:53])
X[:,11:53] = imputer.transform(X[:,11:53])


#Splitting the dataset into test and train set
from sklearn.model_selection import train_test_split
X_train,x_test,Y_train,y_test=train_test_split(X,Y,test_size=0.2,random_state=0)

#Building the ANN
ann = tf.keras.models.Sequential() #buiding the ann by 3 layers
ann.add(tf.keras.layers.Dense(units= 18, activation='relu'))
ann.add(tf.keras.layers.Dense(units= 15, activation='relu'))
ann.add(tf.keras.layers.Dense(units=1 , activation='sigmoid'))

#Applying Callbacks
from keras.callbacks import EarlyStopping
es = EarlyStopping(monitor ="val_loss",  mode ="min" , verbose=1 , patience=10) 
#to prevent the overfitting of the model
cp = tf.keras.callbacks.ModelCheckpoint('model-{epoch:03d}.model',monitor='val_loss',verbose=0,save_best_only=True,mode='auto')
#to save the best epoch model based on the val_loss...it is saved as .model file or as a folder in your working directory

#Training the ANN
ann.compile(optimizer='adam' , loss='binary_crossentropy' ,metrics= ['accuracy']) #training and compiling the ann
ann.fit(X_train,Y_train,batch_size=32,epochs=100,validation_data=(x_test,y_test),callbacks =[cp])

#Predicting the Test result
y_pred = ann.predict(x_test)
y_pred = (y_pred > 0.5) #just to remove the probability


#Making the Confusion Matrix
from sklearn.metrics import confusion_matrix,accuracy_score
cm = confusion_matrix(y_test,y_pred)
ac = accuracy_score(y_test,y_pred)
print("Confusion Matrix :")
print(cm)
print("Accuracy Percentage :", ac*100 ,'%')
